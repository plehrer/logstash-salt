I got the central server to work and was able to ship an event from a remote host to the central server and have the results show up in Kibana as well as a log file on the vagrant central server. I first installed the broker, redis-server on the vagrant instance.  I configured it to bind to ip 10.0.2.15 and to listen on port 6379 which is the default.  The bind ip default is 127.0.0.1 and I commented this out.

I created directories /etc/logstash and /var/log/logstash on the vagrant instance to store the config file central.conf and the log file central.log.

/etc/central.conf:
# This file should be copied to /etc/logstash
input {
  redis {
    host => "127.0.0.1"
    type => "redis-input"
    data_type => "list"
    key => "logstash"
  }
}
output {
  stdout { }
  elasticsearch {
    cluster => "logstash"
  }
}

redis server config file /etc/redis.conf
It is a large file. See ~/logstash-salt/redis/redis.conf
I changed:
bind 127.0.0.1 to
#bind 127.0.0.1
and added line:
bind 10.0.2.15

This was very important. Without getting the bind address the broker, redis, will not work.

The logstash instance on vagrant was created with the command:
sudo java -jar logstash-1.2.2-flatjar.jar agent -v -f /etc/logstash/central.conf -l /var/log/logstash/central.log

The book has an alternative method for creating the instance and running elastic search as a separate instance. Elastic search runs without creating a separate instance by putting this command in central.conf:
embedded => true

init script for book installation of logstash can be found at:
http://logstashbook.com/code/3/logstash-central-init
This file has been included in the repository

Also, I created a yaml file called elasticsearch.yml which is currently resides in the directory as the logstash jar file, but if the book. This is an elasticsearch configuration file.  If elastic search is set up as in the book, then the file should be in directory: /etc/elasticsearch/

Check chapter “Shipping events”


shipper.conf
# configuration file for remote host to ship events to the central server
input {
  file {
    # type => "syslog"
    type => "apache"
    # path => ["/var/log", "/var/asl", "/var/log/messages"]
    path => [ "/var/log/apache2/*" ]
    exclude => ["*.gz", "shipper.log"]
  }
}

output {
  stdout { codec => rubydebug }
  redis {
    host => "127.0.0.1"
    data_type => "list"

    key => "logstash"
  }
}

I changed the type to apache and the path to the apache log files so I can see events triggered from my local apaches web server.  To see this, go to any local website and click on links, load pages, etc and it should ship the event.

The logstash instance on the remote (my local OS X machine) host was created with the line:
sudo java -jar logstash-1.2.3.dev-flatjar.jar agent -f /etc/logstash/shipper.conf -l /var/log/logstash/shipper.log

Note you have to specify the the configuration file and log file in a similar fashion as on the central server (the vagrant instance).  There is an alternative to this which is specified. Check chapter “Shipping events”

init script for running logstash by book method can be found at:
http://logstashbook.com/code/3/logstash-agent-init
This file has been included in the repository

